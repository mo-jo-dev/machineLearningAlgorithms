{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4806d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731fb8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
      "['6', '148', '72', '35', '0', '33.6', '0.627', '50', '1']\n",
      "['1', '85', '66', '29', '0', '26.6', '0.351', '31', '0']\n",
      "['8', '183', '64', '0', '0', '23.3', '0.672', '32', '1']\n",
      "['1', '89', '66', '23', '94', '28.1', '0.167', '21', '0']\n",
      "['0', '137', '40', '35', '168', '43.1', '2.288', '33', '1']\n",
      "['5', '116', '74', '0', '0', '25.6', '0.201', '30', '0']\n",
      "['3', '78', '50', '32', '88', '31', '0.248', '26', '1']\n",
      "['10', '115', '0', '0', '0', '35.3', '0.134', '29', '0']\n",
      "['2', '197', '70', '45', '543', '30.5', '0.158', '53', '1']\n",
      "['8', '125', '96', '0', '0', '0', '0.232', '54', '1']\n",
      "['4', '110', '92', '0', '0', '37.6', '0.191', '30', '0']\n",
      "['10', '168', '74', '0', '0', '38', '0.537', '34', '1']\n",
      "['10', '139', '80', '0', '0', '27.1', '1.441', '57', '0']\n",
      "['1', '189', '60', '23', '846', '30.1', '0.398', '59', '1']\n",
      "['5', '166', '72', '19', '175', '25.8', '0.587', '51', '1']\n",
      "['7', '100', '0', '0', '0', '30', '0.484', '32', '1']\n",
      "['0', '118', '84', '47', '230', '45.8', '0.551', '31', '1']\n",
      "['7', '107', '74', '0', '0', '29.6', '0.254', '31', '1']\n",
      "['1', '103', '30', '38', '83', '43.3', '0.183', '33', '0']\n",
      "['1', '115', '70', '30', '96', '34.6', '0.529', '32', '1']\n",
      "['3', '126', '88', '41', '235', '39.3', '0.704', '27', '0']\n",
      "['8', '99', '84', '0', '0', '35.4', '0.388', '50', '0']\n",
      "['7', '196', '90', '0', '0', '39.8', '0.451', '41', '1']\n",
      "['9', '119', '80', '35', '0', '29', '0.263', '29', '1']\n",
      "['11', '143', '94', '33', '146', '36.6', '0.254', '51', '1']\n",
      "['10', '125', '70', '26', '115', '31.1', '0.205', '41', '1']\n",
      "['7', '147', '76', '0', '0', '39.4', '0.257', '43', '1']\n",
      "['1', '97', '66', '15', '140', '23.2', '0.487', '22', '0']\n",
      "['13', '145', '82', '19', '110', '22.2', '0.245', '57', '0']\n",
      "['5', '117', '92', '0', '0', '34.1', '0.337', '38', '0']\n",
      "['5', '109', '75', '26', '0', '36', '0.546', '60', '0']\n",
      "['3', '158', '76', '36', '245', '31.6', '0.851', '28', '1']\n",
      "['3', '88', '58', '11', '54', '24.8', '0.267', '22', '0']\n",
      "['6', '92', '92', '0', '0', '19.9', '0.188', '28', '0']\n",
      "['10', '122', '78', '31', '0', '27.6', '0.512', '45', '0']\n",
      "['4', '103', '60', '33', '192', '24', '0.966', '33', '0']\n",
      "['11', '138', '76', '0', '0', '33.2', '0.42', '35', '0']\n",
      "['9', '102', '76', '37', '0', '32.9', '0.665', '46', '1']\n",
      "['2', '90', '68', '42', '0', '38.2', '0.503', '27', '1']\n",
      "['4', '111', '72', '47', '207', '37.1', '1.39', '56', '1']\n",
      "['3', '180', '64', '25', '70', '34', '0.271', '26', '0']\n",
      "['7', '133', '84', '0', '0', '40.2', '0.696', '37', '0']\n",
      "['7', '106', '92', '18', '0', '22.7', '0.235', '48', '0']\n",
      "['9', '171', '110', '24', '240', '45.4', '0.721', '54', '1']\n",
      "['7', '159', '64', '0', '0', '27.4', '0.294', '40', '0']\n",
      "['0', '180', '66', '39', '0', '42', '1.893', '25', '1']\n",
      "['1', '146', '56', '0', '0', '29.7', '0.564', '29', '0']\n",
      "['2', '71', '70', '27', '0', '28', '0.586', '22', '0']\n",
      "['7', '103', '66', '32', '0', '39.1', '0.344', '31', '1']\n",
      "['7', '105', '0', '0', '0', '0', '0.305', '24', '0']\n",
      "['1', '103', '80', '11', '82', '19.4', '0.491', '22', '0']\n",
      "['1', '101', '50', '15', '36', '24.2', '0.526', '26', '0']\n",
      "['5', '88', '66', '21', '23', '24.4', '0.342', '30', '0']\n",
      "['8', '176', '90', '34', '300', '33.7', '0.467', '58', '1']\n",
      "['7', '150', '66', '42', '342', '34.7', '0.718', '42', '0']\n",
      "['1', '73', '50', '10', '0', '23', '0.248', '21', '0']\n",
      "['7', '187', '68', '39', '304', '37.7', '0.254', '41', '1']\n",
      "['0', '100', '88', '60', '110', '46.8', '0.962', '31', '0']\n",
      "['0', '146', '82', '0', '0', '40.5', '1.781', '44', '0']\n",
      "['0', '105', '64', '41', '142', '41.5', '0.173', '22', '0']\n",
      "['2', '84', '0', '0', '0', '0', '0.304', '21', '0']\n",
      "['8', '133', '72', '0', '0', '32.9', '0.27', '39', '1']\n",
      "['5', '44', '62', '0', '0', '25', '0.587', '36', '0']\n",
      "['2', '141', '58', '34', '128', '25.4', '0.699', '24', '0']\n",
      "['7', '114', '66', '0', '0', '32.8', '0.258', '42', '1']\n",
      "['5', '99', '74', '27', '0', '29', '0.203', '32', '0']\n",
      "['0', '109', '88', '30', '0', '32.5', '0.855', '38', '1']\n",
      "['2', '109', '92', '0', '0', '42.7', '0.845', '54', '0']\n",
      "['1', '95', '66', '13', '38', '19.6', '0.334', '25', '0']\n",
      "['4', '146', '85', '27', '100', '28.9', '0.189', '27', '0']\n",
      "['2', '100', '66', '20', '90', '32.9', '0.867', '28', '1']\n",
      "['5', '139', '64', '35', '140', '28.6', '0.411', '26', '0']\n",
      "['13', '126', '90', '0', '0', '43.4', '0.583', '42', '1']\n",
      "['4', '129', '86', '20', '270', '35.1', '0.231', '23', '0']\n",
      "['1', '79', '75', '30', '0', '32', '0.396', '22', '0']\n",
      "['1', '0', '48', '20', '0', '24.7', '0.14', '22', '0']\n",
      "['7', '62', '78', '0', '0', '32.6', '0.391', '41', '0']\n",
      "['5', '95', '72', '33', '0', '37.7', '0.37', '27', '0']\n",
      "['0', '131', '0', '0', '0', '43.2', '0.27', '26', '1']\n",
      "['2', '112', '66', '22', '0', '25', '0.307', '24', '0']\n",
      "['3', '113', '44', '13', '0', '22.4', '0.14', '22', '0']\n",
      "['2', '74', '0', '0', '0', '0', '0.102', '22', '0']\n",
      "['7', '83', '78', '26', '71', '29.3', '0.767', '36', '0']\n",
      "['0', '101', '65', '28', '0', '24.6', '0.237', '22', '0']\n",
      "['5', '137', '108', '0', '0', '48.8', '0.227', '37', '1']\n",
      "['2', '110', '74', '29', '125', '32.4', '0.698', '27', '0']\n",
      "['13', '106', '72', '54', '0', '36.6', '0.178', '45', '0']\n",
      "['2', '100', '68', '25', '71', '38.5', '0.324', '26', '0']\n",
      "['15', '136', '70', '32', '110', '37.1', '0.153', '43', '1']\n",
      "['1', '107', '68', '19', '0', '26.5', '0.165', '24', '0']\n",
      "['1', '80', '55', '0', '0', '19.1', '0.258', '21', '0']\n",
      "['4', '123', '80', '15', '176', '32', '0.443', '34', '0']\n",
      "['7', '81', '78', '40', '48', '46.7', '0.261', '42', '0']\n",
      "['4', '134', '72', '0', '0', '23.8', '0.277', '60', '1']\n",
      "['2', '142', '82', '18', '64', '24.7', '0.761', '21', '0']\n",
      "['6', '144', '72', '27', '228', '33.9', '0.255', '40', '0']\n",
      "['2', '92', '62', '28', '0', '31.6', '0.13', '24', '0']\n",
      "['1', '71', '48', '18', '76', '20.4', '0.323', '22', '0']\n",
      "['6', '93', '50', '30', '64', '28.7', '0.356', '23', '0']\n",
      "['1', '122', '90', '51', '220', '49.7', '0.325', '31', '1']\n",
      "['1', '163', '72', '0', '0', '39', '1.222', '33', '1']\n",
      "['1', '151', '60', '0', '0', '26.1', '0.179', '22', '0']\n",
      "['0', '125', '96', '0', '0', '22.5', '0.262', '21', '0']\n",
      "['1', '81', '72', '18', '40', '26.6', '0.283', '24', '0']\n",
      "['2', '85', '65', '0', '0', '39.6', '0.93', '27', '0']\n",
      "['1', '126', '56', '29', '152', '28.7', '0.801', '21', '0']\n",
      "['1', '96', '122', '0', '0', '22.4', '0.207', '27', '0']\n",
      "['4', '144', '58', '28', '140', '29.5', '0.287', '37', '0']\n"
     ]
    }
   ],
   "source": [
    "def read_csv(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = list(reader)\n",
    "        columns = data[0]\n",
    "        data = data[1:]\n",
    "        return data, columns\n",
    "\n",
    "data, columns = read_csv('./diabetes.csv')\n",
    "print(columns)\n",
    "for row in data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "575448d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splitter(X, y, test_size = 0.2):\n",
    "    indices = list(range(len(X)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    test_set_size = int(len(X) * test_size)\n",
    "    \n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    \n",
    "    X_train = np.array([X[i] for i in train_indices])\n",
    "    X_test = np.array([X[i] for i in test_indices])\n",
    "    y_train = np.array([y[i] for i in train_indices])\n",
    "    y_test = np.array([y[i] for i in test_indices])\n",
    "    \n",
    "    return X_test, y_train, X_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02e82213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of X before conversion: [['6', '148', '72', '35', '0', '33.6', '0.627', '50'], ['1', '85', '66', '29', '0', '26.6', '0.351', '31'], ['8', '183', '64', '0', '0', '23.3', '0.672', '32'], ['1', '89', '66', '23', '94', '28.1', '0.167', '21'], ['0', '137', '40', '35', '168', '43.1', '2.288', '33']]\n",
      "First few rows of y before conversion: ['1', '0', '1', '0', '1']\n",
      "First few rows of X after conversion: [[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0], [1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0], [8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0], [1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0], [0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0]]\n",
      "First few rows of y after conversion: [1.0, 0.0, 1.0, 0.0, 1.0]\n",
      "X_test: [[  1.     89.     66.     23.     94.     28.1     0.167  21.   ]\n",
      " [  1.    103.     30.     38.     83.     43.3     0.183  33.   ]\n",
      " [  6.    144.     72.     27.    228.     33.9     0.255  40.   ]\n",
      " [ 10.    125.     70.     26.    115.     31.1     0.205  41.   ]\n",
      " [  5.    139.     64.     35.    140.     28.6     0.411  26.   ]\n",
      " [  2.    141.     58.     34.    128.     25.4     0.699  24.   ]\n",
      " [  0.    100.     88.     60.    110.     46.8     0.962  31.   ]\n",
      " [  9.    171.    110.     24.    240.     45.4     0.721  54.   ]\n",
      " [  2.    197.     70.     45.    543.     30.5     0.158  53.   ]\n",
      " [  5.    117.     92.      0.      0.     34.1     0.337  38.   ]\n",
      " [  6.     92.     92.      0.      0.     19.9     0.188  28.   ]\n",
      " [  3.    158.     76.     36.    245.     31.6     0.851  28.   ]\n",
      " [  7.    196.     90.      0.      0.     39.8     0.451  41.   ]\n",
      " [  2.     74.      0.      0.      0.      0.      0.102  22.   ]\n",
      " [  1.    163.     72.      0.      0.     39.      1.222  33.   ]\n",
      " [  2.     71.     70.     27.      0.     28.      0.586  22.   ]\n",
      " [  2.    110.     74.     29.    125.     32.4     0.698  27.   ]\n",
      " [  2.     90.     68.     42.      0.     38.2     0.503  27.   ]\n",
      " [  0.    118.     84.     47.    230.     45.8     0.551  31.   ]\n",
      " [  2.    100.     66.     20.     90.     32.9     0.867  28.   ]\n",
      " [  2.    109.     92.      0.      0.     42.7     0.845  54.   ]\n",
      " [ 10.    168.     74.      0.      0.     38.      0.537  34.   ]\n",
      " [  6.    148.     72.     35.      0.     33.6     0.627  50.   ]\n",
      " [  5.     44.     62.      0.      0.     25.      0.587  36.   ]\n",
      " [  5.     88.     66.     21.     23.     24.4     0.342  30.   ]\n",
      " [  1.    126.     56.     29.    152.     28.7     0.801  21.   ]\n",
      " [  8.    125.     96.      0.      0.      0.      0.232  54.   ]\n",
      " [  7.    107.     74.      0.      0.     29.6     0.254  31.   ]\n",
      " [  7.    187.     68.     39.    304.     37.7     0.254  41.   ]\n",
      " [  7.    147.     76.      0.      0.     39.4     0.257  43.   ]\n",
      " [  1.     96.    122.      0.      0.     22.4     0.207  27.   ]\n",
      " [ 10.    139.     80.      0.      0.     27.1     1.441  57.   ]\n",
      " [ 13.    145.     82.     19.    110.     22.2     0.245  57.   ]\n",
      " [  2.    112.     66.     22.      0.     25.      0.307  24.   ]\n",
      " [  7.    100.      0.      0.      0.     30.      0.484  32.   ]\n",
      " [  3.     88.     58.     11.     54.     24.8     0.267  22.   ]]\n",
      "y_test: [0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "X_train: [[  4.    110.     92.      0.      0.     37.6     0.191  30.   ]\n",
      " [  4.    103.     60.     33.    192.     24.      0.966  33.   ]\n",
      " [  4.    144.     58.     28.    140.     29.5     0.287  37.   ]\n",
      " [  3.    126.     88.     41.    235.     39.3     0.704  27.   ]\n",
      " [  1.    115.     70.     30.     96.     34.6     0.529  32.   ]\n",
      " [  1.    189.     60.     23.    846.     30.1     0.398  59.   ]\n",
      " [ 11.    143.     94.     33.    146.     36.6     0.254  51.   ]\n",
      " [  7.     81.     78.     40.     48.     46.7     0.261  42.   ]\n",
      " [  5.     95.     72.     33.      0.     37.7     0.37   27.   ]\n",
      " [  1.    101.     50.     15.     36.     24.2     0.526  26.   ]\n",
      " [  6.     93.     50.     30.     64.     28.7     0.356  23.   ]\n",
      " [  4.    134.     72.      0.      0.     23.8     0.277  60.   ]\n",
      " [  1.     81.     72.     18.     40.     26.6     0.283  24.   ]\n",
      " [  1.    146.     56.      0.      0.     29.7     0.564  29.   ]\n",
      " [  2.     85.     65.      0.      0.     39.6     0.93   27.   ]\n",
      " [ 13.    126.     90.      0.      0.     43.4     0.583  42.   ]\n",
      " [  0.    180.     66.     39.      0.     42.      1.893  25.   ]\n",
      " [  8.    183.     64.      0.      0.     23.3     0.672  32.   ]\n",
      " [  0.    146.     82.      0.      0.     40.5     1.781  44.   ]\n",
      " [  2.    100.     68.     25.     71.     38.5     0.324  26.   ]\n",
      " [  7.    106.     92.     18.      0.     22.7     0.235  48.   ]\n",
      " [ 11.    138.     76.      0.      0.     33.2     0.42   35.   ]\n",
      " [  2.     92.     62.     28.      0.     31.6     0.13   24.   ]\n",
      " [  5.    109.     75.     26.      0.     36.      0.546  60.   ]\n",
      " [  4.    123.     80.     15.    176.     32.      0.443  34.   ]\n",
      " [  1.     71.     48.     18.     76.     20.4     0.323  22.   ]\n",
      " [ 13.    106.     72.     54.      0.     36.6     0.178  45.   ]\n",
      " [  1.    103.     80.     11.     82.     19.4     0.491  22.   ]\n",
      " [  0.    109.     88.     30.      0.     32.5     0.855  38.   ]\n",
      " [  0.    137.     40.     35.    168.     43.1     2.288  33.   ]\n",
      " [  3.    113.     44.     13.      0.     22.4     0.14   22.   ]\n",
      " [  8.    176.     90.     34.    300.     33.7     0.467  58.   ]\n",
      " [  7.     83.     78.     26.     71.     29.3     0.767  36.   ]\n",
      " [ 10.    115.      0.      0.      0.     35.3     0.134  29.   ]\n",
      " [  1.    151.     60.      0.      0.     26.1     0.179  22.   ]\n",
      " [  1.     95.     66.     13.     38.     19.6     0.334  25.   ]\n",
      " [ 15.    136.     70.     32.    110.     37.1     0.153  43.   ]\n",
      " [  1.      0.     48.     20.      0.     24.7     0.14   22.   ]\n",
      " [  9.    119.     80.     35.      0.     29.      0.263  29.   ]\n",
      " [  5.    137.    108.      0.      0.     48.8     0.227  37.   ]\n",
      " [  4.    146.     85.     27.    100.     28.9     0.189  27.   ]\n",
      " [  4.    129.     86.     20.    270.     35.1     0.231  23.   ]\n",
      " [  1.     73.     50.     10.      0.     23.      0.248  21.   ]\n",
      " [  0.    101.     65.     28.      0.     24.6     0.237  22.   ]\n",
      " [  7.    133.     84.      0.      0.     40.2     0.696  37.   ]\n",
      " [  1.    122.     90.     51.    220.     49.7     0.325  31.   ]\n",
      " [  8.     99.     84.      0.      0.     35.4     0.388  50.   ]\n",
      " [  7.    150.     66.     42.    342.     34.7     0.718  42.   ]\n",
      " [  1.     97.     66.     15.    140.     23.2     0.487  22.   ]\n",
      " [  7.    103.     66.     32.      0.     39.1     0.344  31.   ]\n",
      " [  7.    159.     64.      0.      0.     27.4     0.294  40.   ]\n",
      " [  0.    125.     96.      0.      0.     22.5     0.262  21.   ]\n",
      " [  1.    107.     68.     19.      0.     26.5     0.165  24.   ]\n",
      " [  9.    102.     76.     37.      0.     32.9     0.665  46.   ]\n",
      " [  0.    131.      0.      0.      0.     43.2     0.27   26.   ]\n",
      " [  7.    105.      0.      0.      0.      0.      0.305  24.   ]\n",
      " [  2.    142.     82.     18.     64.     24.7     0.761  21.   ]\n",
      " [  8.    133.     72.      0.      0.     32.9     0.27   39.   ]\n",
      " [  3.    180.     64.     25.     70.     34.      0.271  26.   ]\n",
      " [  7.    114.     66.      0.      0.     32.8     0.258  42.   ]\n",
      " [  3.     78.     50.     32.     88.     31.      0.248  26.   ]\n",
      " [  7.     62.     78.      0.      0.     32.6     0.391  41.   ]\n",
      " [  0.    105.     64.     41.    142.     41.5     0.173  22.   ]\n",
      " [  1.     79.     75.     30.      0.     32.      0.396  22.   ]\n",
      " [  5.    166.     72.     19.    175.     25.8     0.587  51.   ]\n",
      " [ 10.    122.     78.     31.      0.     27.6     0.512  45.   ]\n",
      " [  5.     99.     74.     27.      0.     29.      0.203  32.   ]\n",
      " [  2.     84.      0.      0.      0.      0.      0.304  21.   ]\n",
      " [  4.    111.     72.     47.    207.     37.1     1.39   56.   ]\n",
      " [  5.    116.     74.      0.      0.     25.6     0.201  30.   ]\n",
      " [  1.     85.     66.     29.      0.     26.6     0.351  31.   ]\n",
      " [  1.     80.     55.      0.      0.     19.1     0.258  21.   ]]\n",
      "X_train after suppression: [[  4.    110.     92.      0.      0.     37.6     0.191  30.   ]\n",
      " [  4.    103.     60.     33.    192.     24.      0.966  33.   ]\n",
      " [  4.    144.     58.     28.    140.     29.5     0.287  37.   ]\n",
      " [  3.    126.     88.     41.    235.     39.3     0.704  27.   ]\n",
      " [  1.    115.     70.     30.     96.     34.6     0.529  32.   ]\n",
      " [  1.    189.     60.     23.    846.     30.1     0.398  59.   ]\n",
      " [ 11.    143.     94.     33.    146.     36.6     0.254  51.   ]\n",
      " [  7.     81.     78.     40.     48.     46.7     0.261  42.   ]\n",
      " [  5.     95.     72.     33.      0.     37.7     0.37   27.   ]\n",
      " [  1.    101.     50.     15.     36.     24.2     0.526  26.   ]\n",
      " [  6.     93.     50.     30.     64.     28.7     0.356  23.   ]\n",
      " [  4.    134.     72.      0.      0.     23.8     0.277  60.   ]\n",
      " [  1.     81.     72.     18.     40.     26.6     0.283  24.   ]\n",
      " [  1.    146.     56.      0.      0.     29.7     0.564  29.   ]\n",
      " [  2.     85.     65.      0.      0.     39.6     0.93   27.   ]\n",
      " [ 13.    126.     90.      0.      0.     43.4     0.583  42.   ]\n",
      " [  0.    180.     66.     39.      0.     42.      1.893  25.   ]\n",
      " [  8.    183.     64.      0.      0.     23.3     0.672  32.   ]\n",
      " [  0.    146.     82.      0.      0.     40.5     1.781  44.   ]\n",
      " [  2.    100.     68.     25.     71.     38.5     0.324  26.   ]\n",
      " [  7.    106.     92.     18.      0.     22.7     0.235  48.   ]\n",
      " [ 11.    138.     76.      0.      0.     33.2     0.42   35.   ]\n",
      " [  2.     92.     62.     28.      0.     31.6     0.13   24.   ]\n",
      " [  5.    109.     75.     26.      0.     36.      0.546  60.   ]\n",
      " [  4.    123.     80.     15.    176.     32.      0.443  34.   ]\n",
      " [  1.     71.     48.     18.     76.     20.4     0.323  22.   ]\n",
      " [ 13.    106.     72.     54.      0.     36.6     0.178  45.   ]\n",
      " [  1.    103.     80.     11.     82.     19.4     0.491  22.   ]\n",
      " [  0.    109.     88.     30.      0.     32.5     0.855  38.   ]\n",
      " [  0.    137.     40.     35.    168.     43.1     2.288  33.   ]\n",
      " [  3.    113.     44.     13.      0.     22.4     0.14   22.   ]\n",
      " [  8.    176.     90.     34.    300.     33.7     0.467  58.   ]\n",
      " [  7.     83.     78.     26.     71.     29.3     0.767  36.   ]\n",
      " [ 10.    115.      0.      0.      0.     35.3     0.134  29.   ]\n",
      " [  1.    151.     60.      0.      0.     26.1     0.179  22.   ]\n",
      " [  1.     95.     66.     13.     38.     19.6     0.334  25.   ]\n",
      " [ 15.    136.     70.     32.    110.     37.1     0.153  43.   ]\n",
      " [  1.      0.     48.     20.      0.     24.7     0.14   22.   ]\n",
      " [  9.    119.     80.     35.      0.     29.      0.263  29.   ]\n",
      " [  5.    137.    108.      0.      0.     48.8     0.227  37.   ]\n",
      " [  4.    146.     85.     27.    100.     28.9     0.189  27.   ]\n",
      " [  4.    129.     86.     20.    270.     35.1     0.231  23.   ]\n",
      " [  1.     73.     50.     10.      0.     23.      0.248  21.   ]\n",
      " [  0.    101.     65.     28.      0.     24.6     0.237  22.   ]\n",
      " [  7.    133.     84.      0.      0.     40.2     0.696  37.   ]\n",
      " [  1.    122.     90.     51.    220.     49.7     0.325  31.   ]\n",
      " [  8.     99.     84.      0.      0.     35.4     0.388  50.   ]\n",
      " [  7.    150.     66.     42.    342.     34.7     0.718  42.   ]\n",
      " [  1.     97.     66.     15.    140.     23.2     0.487  22.   ]\n",
      " [  7.    103.     66.     32.      0.     39.1     0.344  31.   ]\n",
      " [  7.    159.     64.      0.      0.     27.4     0.294  40.   ]\n",
      " [  0.    125.     96.      0.      0.     22.5     0.262  21.   ]\n",
      " [  1.    107.     68.     19.      0.     26.5     0.165  24.   ]\n",
      " [  9.    102.     76.     37.      0.     32.9     0.665  46.   ]\n",
      " [  0.    131.      0.      0.      0.     43.2     0.27   26.   ]\n",
      " [  7.    105.      0.      0.      0.      0.      0.305  24.   ]\n",
      " [  2.    142.     82.     18.     64.     24.7     0.761  21.   ]\n",
      " [  8.    133.     72.      0.      0.     32.9     0.27   39.   ]\n",
      " [  3.    180.     64.     25.     70.     34.      0.271  26.   ]\n",
      " [  7.    114.     66.      0.      0.     32.8     0.258  42.   ]\n",
      " [  3.     78.     50.     32.     88.     31.      0.248  26.   ]\n",
      " [  7.     62.     78.      0.      0.     32.6     0.391  41.   ]\n",
      " [  0.    105.     64.     41.    142.     41.5     0.173  22.   ]\n",
      " [  1.     79.     75.     30.      0.     32.      0.396  22.   ]\n",
      " [  5.    166.     72.     19.    175.     25.8     0.587  51.   ]\n",
      " [ 10.    122.     78.     31.      0.     27.6     0.512  45.   ]\n",
      " [  5.     99.     74.     27.      0.     29.      0.203  32.   ]\n",
      " [  2.     84.      0.      0.      0.      0.      0.304  21.   ]\n",
      " [  4.    111.     72.     47.    207.     37.1     1.39   56.   ]\n",
      " [  5.    116.     74.      0.      0.     25.6     0.201  30.   ]\n",
      " [  1.     85.     66.     29.      0.     26.6     0.351  31.   ]\n",
      " [  1.     80.     55.      0.      0.     19.1     0.258  21.   ]]\n",
      "y_train: [0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "X = [row[:-1] for row in data]  # All columns except the last one\n",
    "y = [row[-1] for row in data]   # Only the last column\n",
    "\n",
    "print(\"First few rows of X before conversion:\", X[:5])\n",
    "print(\"First few rows of y before conversion:\", y[:5])\n",
    "\n",
    "X = [[float(value) for value in row] for row in X]\n",
    "y = [float(value) for value in y]\n",
    "\n",
    "print(\"First few rows of X after conversion:\", X[:5])\n",
    "print(\"First few rows of y after conversion:\", y[:5])\n",
    "\n",
    "X_test, y_train, X_train, y_test = train_test_splitter(X,y,1/3)\n",
    "\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_test:\", y_test)\n",
    "print(\"X_train:\", X_train)\n",
    "np.set_printoptions(suppress=True)  # Suppress scientific notation for small numbers\n",
    "print(\"X_train after suppression:\",X_train)\n",
    "print(\"y_train:\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4a63cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "class Logistic_Regression():\n",
    "    def __init__(self,learning_rate,iterations):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        \n",
    "    #Function for model training\n",
    "    def fit(self, X, Y):\n",
    "        # no_of_training_examples, no_of_features\n",
    "        self.m, self.n = X.shape\n",
    "        #weight initialization\n",
    "        self.W = np.zeros(self.n)\n",
    "        self.b = 0\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        #gradient descent learning\n",
    "        for i in range(self.iterations):\n",
    "            self.update_weights()\n",
    "        return self\n",
    "\n",
    "    #Helper functions to update weights in gradient descent\n",
    "    \n",
    "    def update_weights(self):\n",
    "        A = 1/(1 + np.exp(-(self.X.dot(self.W) + self.b)))\n",
    "        \n",
    "        #claculate gradients\n",
    "        # slf.Y.T => transpose of Y\n",
    "        #self.m => no. of training examples\n",
    "        tmp = (A - self.Y.T) #diff between predicted prob. A and actual labels\n",
    "        tmp = np.reshape(tmp,self.m) # reshape tmp to shape determined by self.m\n",
    "        dW = np.dot(self.X.T, tmp)/self.m # gradient of weights by dot prod b/w transpose of X and tmp\n",
    "        db = np.sum(tmp) / self.m # gradient of bias (db) by taking the sum of all elements in tmp \n",
    "                                  # and then dividing by self.m, the number of training examples\n",
    "        \n",
    "        self.W = self.W - self.learning_rate*dW\n",
    "        self.b = self.b - self.learning_rate*db\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        Z = 1/(1 + np.exp(- (X.dot(self.W) + self.b)))\n",
    "        Y = np.where(Z>0.5,1,0)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f7e410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Logistic_Regression(learning_rate=0.01, iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "504c346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set by our model       :   61.111111111111114\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "correctly_classified = 0\n",
    "\n",
    "count = 0\n",
    "for count in range(np.size(Y_pred)):\n",
    "\n",
    "    if y_test[count] == Y_pred[count]:\n",
    "        correctly_classified += 1\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print( \"Accuracy on test set by our model       :  \", (  \n",
    "  correctly_classified / count ) * 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eedb855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
